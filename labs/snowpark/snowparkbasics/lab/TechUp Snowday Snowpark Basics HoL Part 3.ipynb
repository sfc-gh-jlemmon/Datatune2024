{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b648ee8",
   "metadata": {},
   "source": [
    "# Snowpark Basics HoL Part 3 - Writing to Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed15903",
   "metadata": {},
   "source": [
    "## 3.1 Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e8402-54a4-47da-a6b2-da3d063f934a",
   "metadata": {},
   "source": [
    "### Imports\n",
    "These imports are from our local Python environment, snowparkbasics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7410ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make sure we do not get line breaks when doing show on wide dataframes\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f95920",
   "metadata": {},
   "source": [
    "### Create Snowpark Session\n",
    "Using a credentials file simplifies the HoL but is not recommended as good practice for development or production environments.\n",
    "<br> The Python connector documentation explains how to use other authentication methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5f942-4348-4763-93de-0d0e5f7ed4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creds.json') as f:\n",
    "    connection_parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49090e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(connection_parameters).create()\n",
    "print(f\"Current Database and schema: {session.get_fully_qualified_current_schema()}\")\n",
    "print(f\"Current Warehouse: {session.get_current_warehouse()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc415aea-0acb-4b46-9a85-c99cd27d2d4f",
   "metadata": {},
   "source": [
    "### Create Stage\n",
    "This will be used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a44987-0bd4-43fb-a2bc-6e51c428b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('CREATE OR REPLACE STAGE TRUCK_STAGE').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c0c26",
   "metadata": {},
   "source": [
    "## 3.2 Loading Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442a6bc-3d45-4b7a-ac79-a3dc72c20fb7",
   "metadata": {},
   "source": [
    "### Loading Data into Snowflake\n",
    "We can load data into Snowflake, including running a PUT operation from the Snowpark client.\n",
    "<br> CSV data is a little more complex in that a structure may need to be explicitly defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821e757-05c6-4c9e-b574-b1c9afec5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "put_result = session.file.put('data/truck.csv', \"@raw_pos.truck_stage\", overwrite=True)\n",
    "put_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeebaf2-bbcb-446a-81b9-185945b3868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('LIST @TRUCK_STAGE').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786b224-5d8d-445e-9347-603209a16be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could use sesson.sql\n",
    "# session.sql('COPY INTO TRUCK1 from @truck_stage file_format=(skip_header=1) on_error=continue').collect()\n",
    "\n",
    "# user_schema is used to read from CSV files. For other files it's not needed.\n",
    "truck_schema = T.StructType([T.StructField(\"TRUCK_ID\", T.IntegerType()),\n",
    "    T.StructField(\"MENU_TYPE_ID\", T.IntegerType()),\n",
    "    T.StructField(\"PRIMARY_CITY\", T.StringType()),\n",
    "    T.StructField(\"REGION\", T.StringType()),\n",
    "    T.StructField(\"ISO_REGION\", T.StringType()),\n",
    "    T.StructField(\"COUNTRY\", T.StringType()),\n",
    "    T.StructField(\"ISO_COUNTRY_CODE\", T.StringType()),\n",
    "    T.StructField(\"FRANCHISE_FLAG\", T.IntegerType()),\n",
    "    T.StructField(\"YEAR\", T.IntegerType()),\n",
    "    T.StructField(\"MAKE\", T.StringType()),\n",
    "    T.StructField(\"MODEL\", T.StringType()),\n",
    "    T.StructField(\"EV_FLAG\", T.IntegerType()),\n",
    "    T.StructField(\"FRANCHISE_ID\", T.IntegerType()),\n",
    "    T.StructField(\"TRUCK_OPENING_DATE\", T.DateType())])\n",
    "\n",
    "# We wtill start with a new table. Snowpark copy_into_table will create a table if necessary (but can also copy into an existing populated table).\n",
    "drop_result = session.sql(\"drop table if exists TRUCK1\").collect()\n",
    "\n",
    "# Use the DataFrameReader (session.read below) to read from CSV files.\n",
    "truck_df = session.read.schema(truck_schema).csv(\"@truck_stage\")\n",
    "\n",
    "csv_file_format_options = {\"FIELD_OPTIONALLY_ENCLOSED_BY\": \"'\\\"'\", \"skip_header\": 1}\n",
    "copied_into_result = truck_df.copy_into_table(\"TRUCK1\", format_type_options=csv_file_format_options)\n",
    "copied_into_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747a5369-e79c-4196-9d75-7df6ca033e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"TRUCK1\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33c724-d4ce-426f-ba5f-b4b5dbdf1647",
   "metadata": {},
   "source": [
    "The new infer schema capability can be used but at present requires that the table be loaded via INSERT SELECT rather than COPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0c2be7-1f89-4ab6-a1f0-7ae9c5f1d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_result = session.sql(\"drop table if exists TRUCK2\").collect()\n",
    "infer_df = session.read.option(\"INFER_SCHEMA\", True).option(\"PARSE_HEADER\", True).csv(\"@truck_stage/truck.csv\")\n",
    "infer_df.show()\n",
    "infer_df.write.mode(\"overwrite\").saveAsTable(\"TRUCK2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3dcfdb-7fe6-4525-908e-62a44643064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"TRUCK2\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea5929-551b-4c7c-826c-284bee7040fa",
   "metadata": {},
   "source": [
    "One word of caution using API calls that silently create a table if needed - be aware that if used in the middle of a multi-statement transaction, if they need to create a table, they will close the transaction (as they generate DDL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e40f8a-0ef7-4e91-a132-9810bc885f2d",
   "metadata": {},
   "source": [
    "## 3.3 Writing to Tables\n",
    "We have already seen ways of creating new tables from data. But what if we want to insert, update, or delete existing tables?\n",
    "To keep it simple let's start with a new table TRUCKUS1 just holding US trucks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b67e604-0dbb-4b91-a90d-1d81c447f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "truckus1_df = session.table(\"TRUCK1\").filter(F.col(\"ISO_COUNTRY_CODE\") == \"US\")\n",
    "truckus1_df.write.mode(\"overwrite\").saveAsTable(\"TRUCKUS1\")\n",
    "session.table(\"TRUCKUS1\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f18045b-6912-4cf1-abef-7e2bc0c0602b",
   "metadata": {},
   "source": [
    "### Copying a Table\n",
    "The following will use INSERT...SELECT. Currently to CLONE a table requires session.sql."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b85025-8601-4101-9685-777f2e382f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "truckus2_df = session.table(\"TRUCKUS1\")\n",
    "truckus2_df.write.mode(\"overwrite\").saveAsTable(\"TRUCKUS2\")\n",
    "session.table(\"TRUCKUS2\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a9be33-c745-433d-992a-b04d88960c1e",
   "metadata": {},
   "source": [
    "Let's create a new set of data by adding 1000 to the original truck ids.\n",
    "<br>(We could also use withColumn, reusing the column name, to update TRUCK_ID but it moves the column to the end...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f31666-958b-4bf6-9bd0-9a8bf1c236e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "truck1000_df = truckus2_df.select((F.col(\"TRUCK_ID\") + 1000).alias(\"TRUCK_ID\"), F.col(\"MENU_TYPE_ID\"), F.col(\"PRIMARY_CITY\"), F.col(\"REGION\"),\n",
    "        F.col(\"ISO_REGION\"), F.col(\"COUNTRY\"), F.col(\"ISO_COUNTRY_CODE\"), F.col(\"FRANCHISE_FLAG\"), F.col(\"YEAR\"), F.col(\"MAKE\"), \n",
    "        F.col(\"MODEL\"), F.col(\"EV_FLAG\"), F.col(\"FRANCHISE_ID\"), F.col(\"TRUCK_OPENING_DATE\" ))\n",
    "truck1000_df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c31cf8-5b9c-41f1-bcab-20967747a39e",
   "metadata": {},
   "source": [
    "### Inserting to a Table\n",
    "Currently there isn't an explicit insert API call. This call will insert an additional 75 rows to TRUCKUS1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05786ed4-aaaa-4d7a-a03c-5758fdbff2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "truck1000_df.write.mode('append').saveAsTable(\"TRUCKUS1\")\n",
    "session.table(\"TRUCKUS1\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e777a5b-7c0a-45ca-bdb2-5ba65fd78fe3",
   "metadata": {},
   "source": [
    "## 3.4 Updating, Deleting and Merging\n",
    "Currently updating, deleting and merging data in or from a table can be done via snowpark.Table.\n",
    "<br>Note that the new Python 'core' API is likely to introduce new calls for tables in the next few months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991392a0-d909-45db-b483-aa45d3915843",
   "metadata": {},
   "source": [
    "### Updating a Table\n",
    "Let's update the TRUCKUS2 table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4272f04-e320-4292-a9d8-390f7193b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=session.table(\"TRUCKUS2\")\n",
    "t.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174b7f4a-4735-4cb3-8540-5b857a03eba2",
   "metadata": {},
   "source": [
    "We can list columns to update and a condition in the **Table.update()** method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c634f6-3590-4ed7-aa9b-5536bc2f5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.update({\"FRANCHISE_FLAG\" : 99}, F.col(\"ISO_REGION\")==\"CA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd221c-71a8-45f7-bb06-c652df0369c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"TRUCKUS2\").filter(F.col(\"ISO_REGION\") ==\"CA\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1c057b-8afb-4694-9e77-418c79e09694",
   "metadata": {},
   "source": [
    "We can also update one table based on values in another table - in this case TRUCKUS1 based on values in TRUCKUS2.\n",
    "<br>This should update only the intiial set of TRUCKUS1 rows which match the TRUCKUS2 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ae674-9c32-4472-9e4a-183f691be740",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = session.table(\"TRUCKUS2\") \n",
    "target_df = session.table(\"TRUCKUS1\")\n",
    "target_df.update({\"FRANCHISE_FLAG\" : source_df[\"FRANCHISE_FLAG\"]}, F.col(\"TRUCK_ID\") == source_df[\"TRUCK_ID\"],source_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e69cd8-b176-4744-89d8-f7cd4788c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"TRUCKUS1\").filter(F.col(\"ISO_REGION\") ==\"CA\").show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4906c9d4-b245-4731-a574-46b5ad164e56",
   "metadata": {},
   "source": [
    "### Deleting from a Table\n",
    "We can list columns and a condition in the **Table.delete()** method. Let's delete from TRUCK3 based on a condtition.\n",
    "<br>We delete based on the FRANCHISE_FLAG, but that is the same as all the rows from CA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f302b3-d28d-4464-938f-9c178d4fbd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=session.table(\"TRUCKUS2\")\n",
    "t.delete(F.col(\"FRANCHISE_FLAG\") == 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12cf372-3171-4f93-8e0a-ca52d418a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"TRUCKUS2\").filter(F.col(\"ISO_REGION\") ==\"CA\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37833a-fb61-4181-aac9-4706566a2451",
   "metadata": {},
   "source": [
    "We can also delete one table based on values in another table.  Here we use the remaining 60 TRUCKUS2 rows to provide a set of keys to delete from the TRUCKUS1 table, leaving the additional rows with plus-1000 kys and the original CA rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca41c77-1430-444a-96b1-13a6af1b77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = session.table(\"TRUCKUS2\")\n",
    "target_df = session.table(\"TRUCKUS1\")\n",
    "target_df.delete(F.col(\"TRUCK_ID\") == source_df[\"TRUCK_ID\"],source_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef5150a-05d4-4cd9-818e-ec65d6648509",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"TRUCKUS1\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9820e-e91c-4924-a205-05899b5c0b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"TRUCKUS2\").show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7780a839",
   "metadata": {},
   "source": [
    "### Simple Merge Example\n",
    "Merging can get complicated to follow whether in SQL or any other language!  \n",
    "Here is a much simpler example using a table we create inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e604fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.create_dataframe([(10, \"old\"), (10, \"unknown\"), (11, \"old\")],\n",
    "      schema=[\"key\", \"value\"]\n",
    "   ).write.save_as_table(\"my_table\", mode=\"overwrite\", table_type=\"temporary\")\n",
    "\n",
    "target = session.table(\"my_table\")\n",
    "\n",
    "source = session.create_dataframe([(10, \"new\"), (12, \"new\"), (13, \"new\")],\n",
    "   schema=[\"key\", \"value\"])\n",
    "\n",
    "target.merge(source,\n",
    "   (target.key == source.key) & (target.value == \"unknown\"),\n",
    "   [F.when_matched().update({\"value\": source[\"value\"]}),\n",
    "   F.when_not_matched().insert({\"key\": source[\"key\"],\"value\": source[\"value\"]})])\n",
    "\n",
    "session.table(\"my_table\").sort(F.col('KEY')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67260431-12fc-4384-a110-a5421a3ddd93",
   "metadata": {},
   "source": [
    "## 3.X YOUR TURN!\n",
    "Here is the challenge:\n",
    "<br>Using the infer capability, create a new ONETRUCKHEADER table by loading from the header.csv file.\n",
    "<br>Then update the new table to set SHIFT_ID to 99.\n",
    "<br>Create another table TWOTRUCKHEADER by copying data from ORDER_HEADER with TRUCK_ID 122 or 123.\n",
    "<br>Update TWOTRUCKHEADER setting the SHIFT_ID to the one from ONETRUCKHEADER for the same ORDER_ID.\n",
    "<br>Finally check the update worked e.g. count TWOTRUCKHEADER rows grouped by TRUCK_ID and SHIFT_ID."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e80c981",
   "metadata": {},
   "source": [
    "### Create a stage and PUT the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe795a8-23af-4f63-b65f-75fbde35a4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138f7e1-6fed-43ae-b56d-bb57309e53cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f4eaceb-b960-4103-84b6-c96baf2ae849",
   "metadata": {},
   "source": [
    "### Now use the infer capability to create and then load the ONETRUCKHEADER table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd3a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25683b84-e027-4e5e-beea-334c1ed73389",
   "metadata": {},
   "source": [
    "### Update ONETRUCKHEADER to set the SHIFT_ID to 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228b6c5-698f-490c-8e04-9c9818328fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc09aaf8",
   "metadata": {},
   "source": [
    "### Create a TWOTRUCKHEADER table for TRUCK_ID 122 or 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dd7e50-4eb4-47e3-af53-3ca409bf74cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed126de8-bff3-42d7-9905-5c5f4131f06a",
   "metadata": {},
   "source": [
    "### Update TWOTRUCKHEADER SHIFT_IDs based on ONETRUCKHEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483e0a4-3042-4edb-98d9-1eb25957eb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bebacf2-ff72-4c61-830e-3fefa73b6ea6",
   "metadata": {},
   "source": [
    "### Count rows in TWOTRUCKHEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b2003-6495-4b08-ac39-e18114ea1003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7287f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29836686-a04f-4fd3-aece-070902674c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
